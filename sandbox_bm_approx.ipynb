{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sobol_lib import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gen_mat import *\n",
    "from block_rect_maxvol import *\n",
    "import re\n",
    "import os\n",
    "from matplotlib import cm\n",
    "from mva_test import *\n",
    "from nmb_error import *\n",
    "import itertools\n",
    "from ipywidgets import interactive, interact, widgets\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from maxvolpy.maxvol import rect_maxvol, maxvol\n",
    "from numba import jit\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "print (os.environ['OMP_NUM_THREADS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_expr = 1 # Adding this num to output fn for distinguish between experiments  (not used for now)\n",
    "nder = 2 # Dimension\n",
    "ToLoadSet = False # whether to load settigns form file\n",
    "\n",
    "cut_radiuses = [0.005]\n",
    "inital_points_distribs = ['LHS']\n",
    "\n",
    "if ToLoadSet:\n",
    "    from sandbox_bm_approx_settings import *\n",
    "else:\n",
    "    dir_str = './cr_talk'\n",
    "    #dir_str = os.path.join(os.environ['HOME'], 'work/res/bm-big/')\n",
    "    num_points_for_big_matrix = 6000 # number of points for big matrix\n",
    "    max_row =  18                   # Maximum number of points taken in experiments\n",
    "    max_expansion = 7         # number of columns in big matrix in (nder+1) units\n",
    "    min_expansion = 3        # minimal number of columns in experiments in (nder+1) units\n",
    "    \n",
    "\n",
    "    n_test = 30000    # points on test grid (for calculating error on final step)\n",
    "    poly = cheb       # used polinomials\n",
    "\n",
    "    domain_type = None    #possible types: 'blob', 'ellipse', 'plane', 'rhombus', 'circle'\n",
    "    \n",
    "    \n",
    "#####\n",
    "dir_pdf = os.path.join(dir_str, \"pdf\")\n",
    "try:\n",
    "    os.makedirs(dir_pdf)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "ToTakePointsFromFile = False # (not used for now)\n",
    "\n",
    "# ---------------------------------\n",
    "p_size = (nder+1)*max_row #number of rows in big matrix\n",
    "\n",
    "### generating test points\n",
    "points_test = complex_area_pnts_gen(n_test, nder, distrib='LHS', mod = domain_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the new most general environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating test\n",
    "for inital_points_distrib in inital_points_distribs:\n",
    "    points_fn = 'taken_points_{}'.format(inital_points_distrib)\n",
    "    x = complex_area_pnts_gen(num_points_for_big_matrix, nder, distrib='lhs', mod = domain_type)\n",
    "\n",
    "    A = GenMat(p_size, x, poly=poly, debug=False, pow_p=1)\n",
    "    A = matrix_prep(A, nder+1)\n",
    "    \n",
    "    np.savez(os.path.join(dir_str, points_fn), x=x, points_test=points_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fn_pre_pdf = \"distrib={}\".format(inital_points_distrib)\n",
    "    for cut_radius in cut_radiuses:\n",
    "        f = open(os.path.join(dir_str, \"distrib={}_radius={}\".format(inital_points_distrib, cut_radius) + '.txt'), \"w\")\n",
    "        for expansion in range(min_expansion, max_expansion):\n",
    "                    for N_rows_ex in range(max_row, expansion, -1): # It's not the way people do...\n",
    "                        N_rows = N_rows_ex*(nder+1)\n",
    "                        fnpdf = os.path.join(dir_pdf, fn_pre_pdf + \"_expansion={}_N_rows_ex={}.pdf\".format(expansion, N_rows_ex))\n",
    "                        try:\n",
    "                            taken_points = test_bm(A, x,nder, expansion, N_rows, cut_radius = cut_radius,to_save_pivs=N_rows_ex==max_row, \n",
    "                                                       fnpdf=fnpdf)\n",
    "                        except SingularError as err:\n",
    "                            print ('not full column rank with expansion={}, N_rows_ex={}, err={}'.format(\n",
    "                                                                expansion, N_rows_ex, err.value)) \n",
    "                            #continue\n",
    "                            break\n",
    "                            \n",
    "\n",
    "\n",
    "                        taken_points.tofile(f, sep=\" \")\n",
    "                        f.write(\"_Nrows={}_expans={}\\n\".format(N_rows, expansion))\n",
    "                        f.flush()\n",
    "\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New version with dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data extraction\n",
    "dir_str = './'\n",
    "dir_points = os.path.join(dir_str, \"doe_exp_40-90-Square/\")\n",
    "domain_type= None\n",
    "ndim = 2\n",
    "points_distrib = 'LHS'\n",
    "#rad = \"0.015\"\n",
    "taken_points = np.load(dir_points + \"taken_points_\" + points_distrib + \".npz\")\n",
    "#taken_points = np.load(dir_points + \"taken_points_\" + points_distrib + \"_rad=\" + rad + \".npz\")\n",
    "x = taken_points['x']\n",
    "points_test = taken_points['points_test']\n",
    "fn = dir_points + \"distrib=\" + points_distrib + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### .txt processing\n",
    "N_row, N_col, p_indices = file_extraction(dir_points + \"distrib=\" + points_distrib + \".txt\")\n",
    "min_exp, max_exp = np.min(N_col), np.max(N_col)\n",
    "max_pts = int(np.max(N_row) / (ndim + 1))\n",
    "design_dict = extracted_design_to_dict(N_row, N_col, p_indices, ndim + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment setup\n",
    "error_blank = {'lhs': [],'sobol': [],'random': []}\n",
    "to_plot_maxvol_error = True\n",
    "plot_mode = ('fixed_num_of_functions', 100)\n",
    "\n",
    "solve_all_mesh = False\n",
    "N_iter = 4\n",
    "col_to_fix = []\n",
    "point_to_fix = []\n",
    "slice_coeff = []\n",
    "function = f_sincos\n",
    "\n",
    "exp_solve = [[],[],[]]\n",
    "if solve_all_mesh:\n",
    "    exp_solve = [np.unique(np.arange(N_col[0],N_col[-1])),[],None]\n",
    "    exp_plot[0] = col_to_fix\n",
    "    exp_plot[1] = point_to_fix\n",
    "    exp_plot[2] = slice_coeff\n",
    "else:\n",
    "    exp_solve[0] = col_to_fix\n",
    "    exp_solve[1] = point_to_fix\n",
    "    exp_solve[2] = slice_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_storage_dict = process_experiment_scheme(exp_solve, error_blank, ndim + 1, min_exp, max_exp, max_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_error_calculation(N_iter, function, points_test, error_storage_dict, poly_basis=cheb, derivative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmaxvol_stat = bmaxvol_error(function, points_test, x, design_dict, error_storage_dict, poly_basis=cheb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmaxvol_visual = process_maxvol_error_for_plot(bmaxvol_stat, ndim + 1, min_exp, max_exp, max_pts, plot_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation_data = process_error_for_plot(error_blank, error_storage_dict, ndim + 1, min_exp, max_exp, max_pts, plot_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = f_branin\n",
    "tensor_name = 'error_{}'.format(function.__name__)\n",
    "error_saved_t = np.load(os.path.join(dir_points, tensor_name) + \".npz\", allow_pickle=True)\n",
    "error_storage_dict = error_saved_t['nmb_error_dict'].item()\n",
    "bmaxvol_stat = error_saved_t['maxvol_error_dict'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "confidence = True\n",
    "plt.yscale('log')\n",
    "for points_type in error_blank:\n",
    "    plt.plot(visualisation_data[points_type][0], visualisation_data[points_type][1], label = points_type)\n",
    "    if confidence:\n",
    "        plt.fill_between(visualisation_data[points_type][0], visualisation_data[points_type][2], visualisation_data[points_type][3],alpha = 0.4,label = '95% CI_'+points_type)\n",
    "\n",
    "if to_plot_maxvol_error:\n",
    "    plt.plot(bmaxvol_visual[0], bmaxvol_visual[1], label = 'Bmaxvol')\n",
    "\n",
    "if plot_mode[0]==\"fixed_num_of_functions\":\n",
    "    plt.xlabel('Number of points', fontsize=10)\n",
    "#         fnpdf = dir_points+'err(cols)_points={}_func={}.pdf'.format(experiment_params[1],experiment_params[2])\n",
    "elif plot_mode[0]==\"fixed_num_of_points\":\n",
    "    plt.xlabel('Number of functions', fontsize=10)\n",
    "#         fnpdf = dir_points+'err(rows)_monoms={}_func={}.pdf'.format(experiment_params[1],experiment_params[2])\n",
    "elif plot_mode[0]==\"slice\":\n",
    "    plt.xlabel('Number of points', fontsize=10)\n",
    "#         fnpdf = dir_points+'err(points)_coef={}_func={}.pdf'.format(experiment_params[1],experiment_params[2])\n",
    "plt.ylabel('Approximation error, $\\epsilon$', rotation=90, labelpad=5)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(dir_points + \"error_comparison_{}.jpg\".format(function.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_factors =[1.25,1.4,1.75,2.0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12,9))\n",
    "confidence = True\n",
    "\n",
    "\n",
    "for i, slice_coeff in enumerate(slice_factors):\n",
    "    plot_mode = ('slice', slice_coeff)\n",
    "    bmaxvol_visual = process_maxvol_error_for_plot(bmaxvol_stat, ndim + 1, min_exp, max_exp, max_pts, plot_mode)\n",
    "    visualisation_data = process_error_for_plot(error_blank, error_storage_dict, ndim + 1, min_exp, max_exp, max_pts, plot_mode)\n",
    "    \n",
    "    ax[i//2, i % 2].set_yscale('log')\n",
    "    ax[i//2, i % 2].set_title('slice coeff = {}'.format(slice_coeff))\n",
    "    ax[i//2, i % 2].set_xlabel('Number of points', fontsize=10)\n",
    "    for points_type in error_blank:\n",
    "        ax[i//2, i % 2].plot(visualisation_data[points_type][0], visualisation_data[points_type][1], label = points_type)\n",
    "        if confidence:\n",
    "            ax[i//2, i % 2].fill_between(visualisation_data[points_type][0], visualisation_data[points_type][2], visualisation_data[points_type][3],alpha = 0.4,label = '95% CI_'+points_type)\n",
    "\n",
    "    if to_plot_maxvol_error:\n",
    "        ax[i//2, i % 2].plot(bmaxvol_visual[0], bmaxvol_visual[1], label = 'Bmaxvol')\n",
    "    ax[i//2, i % 2].grid(True)\n",
    "handles, labels = ax[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right')\n",
    "fig.suptitle('Error at function {}'.format(function.__name__))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"error_comparison_{}.jpg\".format(function.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data extraction\n",
    "dir_str = './'\n",
    "dir_points = os.path.join(dir_str, \"doe_exp_dim=2_20-50-Square/\")\n",
    "domain_type= None\n",
    "nder = 2\n",
    "points_distrib = 'LHS'\n",
    "#rad = \"0.015\"\n",
    "taken_points = np.load(dir_points + \"taken_points_\" + points_distrib + \".npz\")\n",
    "#taken_points = np.load(dir_points + \"taken_points_\" + points_distrib + \"_rad=\" + rad + \".npz\")\n",
    "x = taken_points['x']\n",
    "points_test = taken_points['points_test']\n",
    "fn = dir_points + \"distrib=\" + points_distrib + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### .txt processing\n",
    "N_row, N_col, p_indices = file_extraction(dir_points + \"distrib=\" + points_distrib + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_preproc(N_row,N_col,exp_mask,step_along=1,new_extr_path = None):\n",
    "    if new_extr_path:\n",
    "        N_row, N_col, p_indices = file_extraction(new_extr_path)\n",
    "    ndim = 3\n",
    "    ent=[N_col, N_row]\n",
    "    indx = np.array(())\n",
    "    for axis, indxs_to_extract in enumerate(exp_mask[:-1]):\n",
    "        indx = np.concatenate((np.where(np.in1d(ent[axis], indxs_to_extract))[0][::step_along], indx))\n",
    "    if exp_mask[-1]:\n",
    "        indx = np.concatenate((np.where(N_row//ndim == np.around(exp_mask[-1]*N_col))[0][::step_along],indx))\n",
    "    indx = np.unique(indx)\n",
    "    return(indx.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def mult_error_tensor(N_iter, N_row, N_col,function, error_set, shape=None):\n",
    "    nder = 2\n",
    "    ndim = nder + 1\n",
    "    error_tensor = np.empty((len(error_set), N_col.shape[0], N_iter))\n",
    "    if type(function) is not list:\n",
    "            function = [function]\n",
    "    ValsandNorms = MakeValsAndNorms(function, points_test)\n",
    "    for i in np.arange(N_iter):\n",
    "        print('Iteration #{}'.format(i))\n",
    "        for j, p in enumerate(N_col):\n",
    "            for k, points_type in enumerate(error_set):\n",
    "                x_tmp = complex_area_pnts_gen(N_row[j]//ndim, nder, mod=shape, distrib=points_type)\n",
    "                if points_type=='sobol' and len((np.where(x_tmp == np.array([[0.,0.],])))[0])!=0:\n",
    "\n",
    "                    while True:\n",
    "                        x_tmp = complex_area_pnts_gen(N_row[j]//ndim, nder, mod=domain_type, distrib='sobol')\n",
    "                        if len((np.where(x_tmp == np.array([[0.,0.],])))[0])==0:\n",
    "                            break\n",
    "                _, error_tensor[k][j,i] = LebesgueConst(x_tmp, N_col[j]*ndim, poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "\n",
    "    return(error_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def bmaxvol_error(function,points_test,p_indices, ix):\n",
    "    error_bmaxvol, Leb_e = [], []\n",
    "    nder = 2\n",
    "\n",
    "    if type(function) is not list:\n",
    "            function = [function]\n",
    "\n",
    "    ValsandNorms = MakeValsAndNorms(function, points_test)\n",
    "    for j, p in enumerate(p_indices[ix]):\n",
    "        _,b = LebesgueConst(x[p], N_col[ix][j]*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "        error_bmaxvol.append(b)\n",
    "    bmv = np.array(error_bmaxvol).reshape((1,len(error_bmaxvol)))\n",
    "    return(bmv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_tensor_plot(fn, mean_tensor, T_up, T_down,error_set, inx,ix_g,experiment_params, confidence = False):\n",
    "    ndim = 3\n",
    "    N_row, N_col,_ = file_extraction(fn)\n",
    "    ax = experiment_params[0]\n",
    "    if experiment_params[0] == 2:\n",
    "        ax = 0\n",
    "    N_row //= ndim\n",
    "    N_col *= ndim\n",
    "    ent_list = [N_row[ix_g], N_col[ix_g]]\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    plt.yscale('log')\n",
    "    for k, points_type in enumerate(error_set):\n",
    "        plt.plot(ent_list[ax][inx], mean_tensor[k][inx], label = points_type)\n",
    "        if confidence and points_type != 'BMaxvol' and points_type!= 'Maxvol':\n",
    "            plt.fill_between(ent_list[ax][inx], T_down[k][inx], T_up[k][inx],alpha = 0.4,label = '95% CI_'+points_type)\n",
    "    \n",
    "    if experiment_params[0]==1:\n",
    "        plt.xlabel('Number of basis functions', fontsize=10)\n",
    "#         fnpdf = dir_points+'err(cols)_points={}_func={}.pdf'.format(experiment_params[1],experiment_params[2])\n",
    "    elif experiment_params[0] == 0:\n",
    "        plt.xlabel('Number of points', fontsize=10)\n",
    "#         fnpdf = dir_points+'err(rows)_monoms={}_func={}.pdf'.format(experiment_params[1],experiment_params[2])\n",
    "    else:\n",
    "        plt.xlabel('Number of points', fontsize=10)\n",
    "#         fnpdf = dir_points+'err(points)_coef={}_func={}.pdf'.format(experiment_params[1],experiment_params[2])\n",
    "    plt.ylabel('Approximation error, $\\epsilon$', rotation=90, labelpad=5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "#     plt.savefig(fnpdf)\n",
    "    plt.close(fig)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment setup\n",
    "error_set = ['lhs','sobol','random']\n",
    "non_random_error_set = ['BMaxvol']\n",
    "\n",
    "\n",
    "solve_all_mesh = False\n",
    "N_iter = 5\n",
    "col_to_fix = []\n",
    "point_to_fix = []\n",
    "slice_coeff = 2\n",
    "function = f_sincos\n",
    "\n",
    "exp_solve = [[],[],[]]\n",
    "if solve_all_mesh:\n",
    "    exp_solve = [np.unique(np.arange(N_col[0],N_col[-1])),[],None]\n",
    "    exp_plot[0] = col_to_fix\n",
    "    exp_plot[1] = point_to_fix\n",
    "    exp_plot[2] = slice_coeff\n",
    "else:\n",
    "    exp_solve[0] = col_to_fix\n",
    "    exp_solve[1] = point_to_fix\n",
    "    exp_solve[2] = slice_coeff\n",
    "    exp_plot = exp_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_row = np.hstack([np.arange(num_points_max,i,-1) for i in range(min_col_exp,max_col_exp)])\n",
    "#N_col = np.hstack([i*np.ones(np.arange(num_points_max,i,-1).shape[0]) for i in range(min_col_exp,max_col_exp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = index_preproc(N_row,N_col,exp_solve,step_along=1, new_extr_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error calculation\n",
    "function_set = [function]\n",
    "for function in function_set:\n",
    "    error_tensor = mult_error_tensor(N_iter,N_row[ix], N_col[ix],function, error_set, shape=domain_type)\n",
    "#     tensor_name = 'error_tensor_{}_{}_exp2_1'.format(domain_type, function.__name__)\n",
    "#     np.savez(os.path.join(dir_points, tensor_name), error_tensor=error_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_name = 'error_{}'.format(function.__name__)\n",
    "error_saved_t = np.load(os.path.join(dir_points, tensor_name) + \".npz\")\n",
    "error_tensor = error_saved_t['error_tensor']\n",
    "\n",
    "\n",
    "# full_tensor = np.concatenate((error_tensor,error_tensor_add),axis=2)\n",
    "\n",
    "# tensor_name = 'error_tensor_{}_{}_exp2'.format(domain_type, function.__name__)\n",
    "# np.savez(os.path.join(dir_points, tensor_name), error_tensor=full_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmxvol_error = bmaxvol_error(function,points_test, p_indices, ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting\n",
    "error_set = ['lhs','sobol','random']\n",
    "non_random_error_set = ['BMaxvol']\n",
    "function_set = [function]\n",
    "error_set += non_random_error_set\n",
    "for function in function_set:\n",
    "#     tensor_name = 'error_tensor_{}_{}_exp2'.format(domain_type, function.__name__)\n",
    "#     error_saved = np.load(os.path.join(dir_points, tensor_name) + \".npz\")\n",
    "#     error_tensor = error_saved['error_tensor']\n",
    "    print(error_tensor.shape)\n",
    "    z = 1.28    #z-value for 95% confidence interval\n",
    "    k = z / np.sqrt(error_tensor.shape[2])    #correcting by a square root from a number of experiments\n",
    "    mean_tensor = np.mean(error_tensor,axis = 2)\n",
    "    T_up = mean_tensor + k*np.std(error_tensor, axis = 2)\n",
    "    T_down = mean_tensor - k*np.std(error_tensor, axis = 2)\n",
    "#     \n",
    "    mean_tensor = np.concatenate((mean_tensor,bmxvol_error),axis=0)\n",
    "    \n",
    "    for axis, jx in enumerate(exp_plot[:-1]):\n",
    "        for count, fixed_entity in enumerate(jx):\n",
    "            local_design = [[],[],[]]\n",
    "            local_design[axis] = fixed_entity\n",
    "            ix_internal = index_preproc(N_row[ix],N_col[ix],local_design,step_along=1, new_extr_path = None)\n",
    "            error_tensor_plot(fn, mean_tensor,T_up,T_down,error_set, ix_internal,ix,[axis, fixed_entity,function.__name__], confidence = True)\n",
    "    if exp_plot[-1]:\n",
    "        local_design = [[],[],[]]\n",
    "        local_design[2] = exp_plot[-1]\n",
    "        ix_internal = index_preproc(N_row[ix],N_col[ix],local_design,step_along=1, new_extr_path = None)\n",
    "        error_tensor_plot(fn, mean_tensor,T_up,T_down,error_set, ix_internal,ix,[2,exp_plot[-1],function.__name__], confidence = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_wave_shape(x[p_indices[20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_wave_shape(points_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 4\n",
    "x_max = 7\n",
    "pts_max = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxvol_test(x, nder, N_row, N_col, poly):\n",
    "    ndim = nder + 1\n",
    "    maxvol_p_indices = np.empty((N_col.shape[0],),dtype=object)\n",
    "    for i in np.unique(N_col):\n",
    "        #p_size = np.unique(N_col)[i]#*ndim\n",
    "        p_size = i \n",
    "        A = GenMat(p_size, x, poly=poly, debug=False, pow_p=1)\n",
    "        A = A[:x.shape[0]]\n",
    "        loc_idx = np.where(N_col == i)[0]\n",
    "        loc_max_pts = N_row[loc_idx][np.argmax(N_row[loc_idx])] // ndim\n",
    "        taken_points_nonblock,_ = rect_maxvol(A, maxK = loc_max_pts, minK = loc_max_pts)\n",
    "        for j in loc_idx:\n",
    "            maxvol_p_indices[j] = list(taken_points_nonblock[:N_row[j] // ndim])\n",
    "        \n",
    "    return(maxvol_p_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GenMat(30, x, poly=cheb, debug=False, pow_p=1)\n",
    "A = A[:x.shape[0]]\n",
    "\n",
    "taken_points_nonblock,_ = rect_maxvol(A, maxK = 38, minK = 38)\n",
    "p1 = taken_points_nonblock[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxvol_p_ind = maxvol_test(x,nder,N_row[ix],N_col[ix],cheb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValsandNorms = MakeValsAndNorms(function, points_test)\n",
    "error_mva = []\n",
    "for j, p in enumerate(maxvol_p_ind):\n",
    "    print(N_col[ix][j],x[p].shape)\n",
    "    _,c = LebesgueConst(x[p], N_col[ix][j]*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "    error_mva.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mva = []\n",
    "for j in range(3,19):\n",
    "    _,c = LebesgueConst(x[p1], j*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "    error_mva.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random points plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_exp = min_expansion\n",
    "col_exp = 40\n",
    "i = np.where(N_col == col_exp)[0][0]\n",
    "taken_indices = p_indices[i]\n",
    "N_points = len(p_indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_plot(len(p_indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = complex_area_pnts_gen(1400, nder, mod='plane', distrib='Sobol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LebesgueConst_w(pnts, l,uwu, poly=cheb,test_pnts=None, pow_p=1, funcs=None):\n",
    "    A = GenMat(l, pnts, poly=poly, debug=False, pow_p=pow_p, ToGenDiff=True)\n",
    "    nder = pnts.shape[1]\n",
    "    A = matrix_prep(A, nder+1)\n",
    "    ewe = np.array([[1],[1],[1]])\n",
    "    weeght = np.kron(uwu,ewe)\n",
    "    C = weeght*A\n",
    "    ABig = GenMat(l, test_pnts, poly=poly, debug=False, pow_p=pow_p, ToGenDiff=False)\n",
    "    F = np.linalg.pinv(A).T.dot(ABig.T)\n",
    "    for f, fvals, fnorm in funcs:\n",
    "        rhs = RHS(f, pnts, derivative = True)\n",
    "        print rhs.shape\n",
    "        print weeght.shape\n",
    "        rhs1 = weeght.T*rhs\n",
    "        rhs1 = rhs1.reshape(rhs1.shape[1])\n",
    "        #rhs = rhs1.reshape(42)\n",
    "        res = np.linalg.norm(F.T.dot(rhs) - fvals, np.inf)/fnorm\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GenMat(6, x, poly=power, debug=False, pow_p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taken_points = np.load(\"piston_10_error.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = taken_points['er']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"piston_10.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_lhs = data['er_lhs']\n",
    "er_r = data['er_r']\n",
    "er_s = data['er_s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_sp(x,y):\n",
    "    b,e = 0.2,0.95\n",
    "    sigma,n = 1/2, 1\n",
    "    r = sp.sqrt(x**2 + y**2)\n",
    "    phi = sp.atan2(y,x)\n",
    "    R = r*sp.sqrt(1 - (e*sp.cos(phi))**2)/b\n",
    "    return((sp.exp(-1*(R**2)/(2*(sigma**2))))*sp.cos(n*phi))\n",
    "\n",
    "def sin_blob_sp(x,y):\n",
    "    a = 0.2\n",
    "    b = 0.8\n",
    "    sigma,n = 1,7\n",
    "    r = sp.sqrt(x**2 + y**2)\n",
    "    phi = sp.atan2(y,x)\n",
    "    R = r*(1/(b + a*sp.cos(n*phi)))\n",
    "    return((sp.exp(-1*(R**2)/(2*(sigma**2))))*(r**2))\n",
    "\n",
    "f_ellipse = symb_to_func(ellipse_sp,    2, True, False, name='Ellipse')  \n",
    "f_sin_blob= symb_to_func(sin_blob_sp,   2, True, False, name='Blob')  \n",
    "\n",
    "f_ellipse.diff    = MakeDiffs(ellipse_sp,  2)\n",
    "f_sin_blob.diff   = MakeDiffs(sin_blob_sp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "a = 1.1\n",
    "X = np.linspace(-a, a, 1000)\n",
    "Y = np.linspace(-a, a, 1000)\n",
    "phi = np.arange(0,2*np.pi, 0.01)\n",
    "b= 0.2\n",
    "e = 0.95\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "#r = (b / np.sqrt(1-(e*np.cos(phi))**2))\n",
    "#xx = r*np.cos(phi)\n",
    "#yy = r*np.sin(phi)\n",
    "\n",
    "r = 0.8 + 0.2*np.cos(7*phi)\n",
    "xx = r*np.cos(phi)\n",
    "yy = r*np.sin(phi)\n",
    "\n",
    "#Z = f_ellipse(X,Y)\n",
    "#Z = f_sin_blob(X,Y)\n",
    "Z = f_gauss_doubl(X,Y) - 2\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.summer,\n",
    "                       linewidth=0,label = 'Trigonometric')\n",
    "#fc = ax.plot(xx, yy,'bo', zs=0, zdir='z', label='curve in (x,y)')\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-1, 1)\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.4, aspect=5)\n",
    "plt.grid(True)\n",
    "#fnpdf = 'ellips.pdf'\n",
    "#plt.savefig(fnpdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = ['0.0','0.01','0.015','0.02','0.025','0.03','0.04','0.05','0.06','0.07','0.08','0.09','0.1','0.11','0.12','0.13','0.15','0.18','0.2','0.25']#,'0.4']\n",
    "funcs = [f_gauss,f_rosenbrock,f_sincos,f_schafferf6,f_roots,f_yaf1,f_gabor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function in funcs:\n",
    "    error_rad = []\n",
    "    #volume = []\n",
    "    for rad in radiuses:\n",
    "        fn = dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\"\n",
    "        N_row, N_col, p_indices = file_extraction(dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\")\n",
    "        ix = index_preproc(N_row,N_col,exp_solve,step_along=1, new_extr_path = None)\n",
    "\n",
    "        #pts = p_indices[ix][0]\n",
    "\n",
    "        #A = GenMat(N_col[ix][0]*(nder+1), x[pts], poly=cheb, debug=False, pow_p=1)\n",
    "        #A = matrix_prep(A, nder+1)\n",
    "        #vol = la.det(A.T @ A)\n",
    "        #volume.append(vol)\n",
    "        bmxvol_error = bmaxvol_error(function,points_test,p_indices,ix)\n",
    "        error_rad.append(bmxvol_error)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 14))\n",
    "\n",
    "    ax.set_xlim(-0.01, 0.26)\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(np.array(radiuses,dtype=float), fontsize=5)\n",
    "    plt.plot(np.array(radiuses,dtype=float),np.array(error_rad)[:,0,0])\n",
    "    plt.xlabel('Erasion radius', fontsize=10)\n",
    "    plt.ylabel('$\\epsilon$')\n",
    "    plt.grid(True)\n",
    "    fnpdf = 'error-rad_fine_func={}.pdf'.format(function.__name__)\n",
    "    plt.savefig(fnpdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted maxvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nder = 2\n",
    "domain_type = None\n",
    "p_size = 9\n",
    "x = complex_area_pnts_gen(10000, nder, distrib='lhs', mod = domain_type)\n",
    "A = GenMat(p_size, x, poly=cheb, debug=False, pow_p=1)\n",
    "A = matrix_prep(A, nder+1)\n",
    "#piv = rect_block_maxvol(A, nder, 18, max_iters=200, rect_tol = 0.05, tol = 0.0,debug = False, to_erase = None)\n",
    "perm, C = block_maxvol(A, nder, tol = 0.05, max_iters=200, swm_upd=True)\n",
    "A = A[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_block_backward_core(C, P, nder, Kmax, t = 0.05, to_erase=None):\n",
    "    ndim = nder + 1\n",
    "    n, m = C.shape\n",
    "    num_block = n // ndim\n",
    "    k = int(Kmax // ndim)\n",
    "    Fl = True\n",
    "    block_index = m // ndim\n",
    "    non_unique_block_piv = np.copy(P[:m:ndim]//ndim)\n",
    "    block_indcs = P[::ndim]//ndim\n",
    "    S = cold_start_tens(C,ndim)\n",
    "\n",
    "    while Fl and block_index < k:\n",
    "        det_list = la.det(np.eye(ndim) + S)\n",
    "        elem = np.argmax(det_list)\n",
    "        \n",
    "        if det_list[elem] > (1 + t):\n",
    "            range_new_block = np.arange(elem*ndim, elem*ndim + ndim)\n",
    "\n",
    "            \n",
    "            #------ update part -----            \n",
    "            block = np.eye(ndim) + C[range_new_block].dot(C[range_new_block].T)\n",
    "            op3 = C.dot(la.solve(block,C[range_new_block]).T)\n",
    "            op4 = np.dot(op3, C[range_new_block])\n",
    "                   \n",
    "            \n",
    "            C = np.hstack((C - op4, op3))\n",
    "            S = cold_start_tens(C,ndim)\n",
    "        \n",
    "            if not np.isin(block_indcs[elem],non_unique_block_piv):\n",
    "                block_index += 1\n",
    "            \n",
    "            non_unique_block_piv = np.hstack((non_unique_block_piv,block_indcs[elem]))\n",
    "        else:\n",
    "            print('No relevant elements found')\n",
    "            Fl = False\n",
    "    print(block_index)\n",
    "    return(non_unique_block_piv, np.unique(non_unique_block_piv))\n",
    "\n",
    "\n",
    "def rect_backward_naive(A,nder,Kmax,t=0.05):\n",
    "    ndim = nder + 1\n",
    "    n, m = A.shape\n",
    "    k = int(Kmax // ndim)\n",
    "    ids = np.copy(A[:m])\n",
    "    C = np.dot(A,np.linalg.pinv(ids))\n",
    "    \n",
    "    block_index = m // ndim\n",
    "    \n",
    "    block_indcs = np.arange(int(n//ndim))\n",
    "    non_unique_block_piv = np.copy(block_indcs[:(int(m//ndim))])\n",
    "    S = cold_start_tens(C,ndim)\n",
    "    \n",
    "    Fl = True\n",
    "    \n",
    "    test_iter = 0\n",
    "    \n",
    "    while Fl and block_index < k and test_iter < 9:\n",
    "        det_list = la.det(np.eye(ndim) + S)\n",
    "        elem = np.argmax(det_list)\n",
    "        print(det_list[elem], elem)\n",
    "        print(det_list[non_unique_block_piv])\n",
    "        print('C shape before extension', C.shape)\n",
    "        if det_list[elem] > (1 + t):\n",
    "            range_new_block = np.arange(elem*ndim, elem*ndim + ndim)\n",
    "            ids = np.vstack((ids,A[range_new_block]))\n",
    "            \n",
    "            if not np.isin(block_indcs[elem],non_unique_block_piv):\n",
    "                block_index += 1\n",
    "            \n",
    "            non_unique_block_piv = np.hstack((non_unique_block_piv,block_indcs[elem]))\n",
    "            \n",
    "            C = np.dot(A,np.linalg.pinv(ids))\n",
    "            S = cold_start_tens(C,ndim)\n",
    "            \n",
    "            print('C shape after extension', C.shape)\n",
    "            print('submatrix shape', ids.shape)\n",
    "            print('-----------------------')\n",
    "            test_iter += 1\n",
    "        else:\n",
    "            print('no elements found')\n",
    "            Fl = False\n",
    "    \n",
    "    \n",
    "    return(non_unique_block_piv, np.unique(non_unique_block_piv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt,ttt = rect_block_backward_core(C, perm, nder, Kmax=30, t = 0.06, to_erase=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy,yyy = rect_backward_naive(A,nder,Kmax = 18,t=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
