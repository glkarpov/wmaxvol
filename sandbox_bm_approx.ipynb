{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sobol_lib import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gen_mat import *\n",
    "from block_rect_maxvol import *\n",
    "import re\n",
    "import os\n",
    "from matplotlib import cm\n",
    "from mva_test import *\n",
    "import itertools\n",
    "from ipywidgets import interactive, interact, widgets\n",
    "from sympy import *\n",
    "from exp_proccess import *\n",
    "from exp_setup import *\n",
    "from scipy.special import comb\n",
    "import pathlib\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.widgets import Slider\n",
    "from maxvolpy.maxvol import rect_maxvol, maxvol\n",
    "from numba import jit, njit\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "print (os.environ['OMP_NUM_THREADS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_expr = 1 # Adding this num to output fn for distinguish between experiments  (not used for now)\n",
    "nder = 4 # Dimension\n",
    "ToLoadSet = False # whether to load settigns form file\n",
    "\n",
    "cut_radiuses = [0.005]\n",
    "inital_points_distribs = ['LHS']\n",
    "\n",
    "if ToLoadSet:\n",
    "    from sandbox_bm_approx_settings import *\n",
    "else:\n",
    "    dir_str = './cr_talk'\n",
    "    #dir_str = os.path.join(os.environ['HOME'], 'work/res/bm-big/')\n",
    "    num_points_for_big_matrix = 6000 # number of points for big matrix\n",
    "    max_row =  18                   # Maximum number of points taken in experiments\n",
    "    max_expansion = 7         # number of columns in big matrix in (nder+1) units\n",
    "    min_expansion = 3        # minimal number of columns in experiments in (nder+1) units\n",
    "    \n",
    "\n",
    "    n_test = 30000    # points on test grid (for calculating error on final step)\n",
    "    poly = cheb       # used polinomials\n",
    "\n",
    "    domain_type = None    #possible types: 'blob', 'ellipse', 'plane', 'rhombus', 'circle'\n",
    "    \n",
    "    \n",
    "#####\n",
    "dir_pdf = os.path.join(dir_str, \"pdf\")\n",
    "try:\n",
    "    os.makedirs(dir_pdf)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "ToTakePointsFromFile = False # (not used for now)\n",
    "\n",
    "# ---------------------------------\n",
    "p_size = (nder+1)*max_row #number of rows in big matrix\n",
    "\n",
    "### generating test points\n",
    "points_test = complex_area_pnts_gen(n_test, nder, distrib='LHS', mod = domain_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the new most general environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "cur_pos = str(pathlib.Path().parent.absolute())\n",
    "config.design_cardinality = 150\n",
    "design_pts = complex_area_pnts_gen(config.design_cardinality, 6, distrib='LHS', mod = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.min_expansion = 4\n",
    "config.max_expansion = 6\n",
    "config.expansion_set = None\n",
    "config.design_dimension = 1\n",
    "config.poly = poly_power\n",
    "config.n_iter = 2500\n",
    "config.delta_n = 40\n",
    "\n",
    "config.design_space = design_pts[:,:config.design_dimension]\n",
    "\n",
    "add_str = '-'.join([str(i) for i in [config.max_expansion, \"_lebesgue_dim{}\".format(config.design_dimension)]])\n",
    "dir_str = cur_pos + '/domain_exp_' + add_str\n",
    "\n",
    "\n",
    "worker = Experiment(config, dir_str)\n",
    "worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(dir_str, x=design_pts)\n",
    "x2 = design_pts[:,:5]\n",
    "np.savez(dir_str + 'domain_exp_127-_lebesgue_dim5/domain_dim=5.npz', x = x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data extraction\n",
    "dir_str = './'\n",
    "ndim_input = 4\n",
    "exp_folder = \"domain_exp_70-_lebesgue_dim{}/\".format(ndim_input)\n",
    "dir_points = os.path.join(dir_str, exp_folder)\n",
    "domain_type= None\n",
    "block_approx = True\n",
    "if block_approx:\n",
    "    calibrate = ndim_input + 1\n",
    "else:\n",
    "    calibrate = 1\n",
    "nder = ndim_input - 1\n",
    "points_distrib = 'LHS'\n",
    "\n",
    "design_space = \"domain_dim={}\".format(ndim_input)\n",
    "test_space = \"test_\" + design_space\n",
    "std_design_name = \"designs_dim={}\".format(ndim_input)\n",
    "add_name = \"\"\n",
    "add_name2 = \"_wise_expand_sd\"\n",
    "add_name3 = \"_wise_expand_wd\"\n",
    "add_name4 = \"\"\n",
    "calc_design = std_design_name + add_name4 + \".txt\"\n",
    "# extend_design = \"designs_dim={}_expnd.txt\".format(nder+1)\n",
    "taken_points = np.load(dir_points + design_space + \".npz\")\n",
    "taken_test = np.load(dir_points + test_space + \".npz\")\n",
    "x = taken_points['x']\n",
    "points_test = taken_test['x']\n",
    "#fn = dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### .txt processing\n",
    "N_col, p_indices,iter_n,wts = file_extraction(dir_points + calc_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = Experiment(dir_points + design_space, dir_points + std_design_name + add_name + \".txt\", ndim_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = Experiment(dir_points + design_space, dir_points + std_design_name + add_name2 + \".txt\", ndim_input, 1)\n",
    "ex3 = Experiment(dir_points + design_space, dir_points + std_design_name + add_name3 + \".txt\", ndim_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4 = Experiment(dir_points + design_space, dir_points + std_design_name + add_name4 + \".txt\", ndim_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3.name = r'$|$supp $\\xi|$={}'.format(len(ex1.p_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3.name = r'$|$supp $\\xi|$ fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.name = r'Truncated optimal $\\xi$, $|$supp $\\xi|$={}'.format(len(ex2.p_indices[0])) #\"Equal # and points themselves, diff expansion\"\n",
    "ex3.name = r'Truncated optimal $\\xi$, $|$supp $\\xi|$={}'.format(len(ex3.p_indices[0]))\n",
    "# ex3.name = ex1.name\n",
    "#ex4.name = r'Optimal $\\xi$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = deepcopy(ex1)\n",
    "ex2.name = \"expanded to square\"\n",
    "ex2.change_expans(\"up_to_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4.get_k_points(5, 'equal_to_columns')\n",
    "ex4.update_cardinalities()\n",
    "print(ex4.cardinalities, ex4.expans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.name = r'Optimal $\\tilde{\\xi}$, $U(\\tilde{\\xi}) \\in \\mathbb{R}^{l \\times k}$'#r'Truncated optimal $\\tilde{\\xi}$, $U(\\tilde{\\xi}) \\in \\mathbb{R}^{k \\times k}$'\n",
    "ex1.name = r'Optimal $\\xi$, $U(\\xi) \\in \\mathbb{R}^{k \\times p}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4.name = r'Truncated optimal $\\tilde{\\xi}$'\n",
    "ex1.name = r'Optimal $\\xi$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_card_p(ex, description, marker_set=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(ex.expans, ex.cardinalities, 'go', markersize=1, label=r'|supp $\\xi(p)$|')\n",
    "    if marker_set is None:\n",
    "        pass\n",
    "    else:\n",
    "        ax.plot(x[marker_set], variance_set[marker_set], 'bo', markersize=3, label='Optimal')\n",
    "    ax.set_xlim(0, ex.expans[-1]+5)\n",
    "    ax.xaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(5))\n",
    "    #plt.axis('scaled')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Number of expansion terms, \"+r'$p$')\n",
    "    ax.legend()\n",
    "    plt.grid()\n",
    "    fig.savefig(description+'.pdf', bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_card_p(ex1, dir_points+'card_ndim{}'.format(ndim_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_support(p_indices, percent):\n",
    "    for i, sup_set in enumerate(p_indices):\n",
    "        k = len(sup_set)\n",
    "        delta = round(percent * k)\n",
    "        \n",
    "        for j in range(delta):\n",
    "            sup_set.append(np.random.randint(20000))\n",
    "    return(p_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = deepcopy(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.p_indices = increase_support(ex2.p_indices, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.update_cardinalities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1. 02.03.20\n",
    "#### Ledesgue constant on optimal designs w.r.t. weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_test  = complex_area_pnts_gen(40000, ndim_input, distrib='LHS', mod = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1.error = ex1.lebesgue_all(points_test, function = function)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2.error = ex2.lebesgue_all(points_test, function = function)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3.error = ex3.lebesgue_all(points_test, function = function)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4.error = ex4.lebesgue_all(points_test, function = function)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ex1 - optimal full sequence of designs\n",
    "## ex_ext - expand experiment: k unique cardinalities form the set of expansions\n",
    "def expand_preproc(ex_opt, ex_ext):\n",
    "    print(ex_ext.cardinalities)\n",
    "    print(ex_ext.expans)\n",
    "    border_exp = ex_ext.expans[-1]\n",
    "    k_up = np.where(ex_opt.cardinalities == border_exp)[0][-1]\n",
    "    ex_opt.expans = ex_opt.expans[:k_up+1]\n",
    "    ex_opt.p_indices = ex_opt.p_indices[:k_up + 1]\n",
    "    ex_opt.update_cardinalities()\n",
    "    return(ex_opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = expand_preproc(ex1,ex4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.yscale('log')\n",
    "plt.plot(ex1.error, 'ro', label = 'optimal designs')\n",
    "#plt.plot(Leb_ex2[0], 'bo', label = 'expanded cut')\n",
    "plt.plot(ex4.error, 'go',label = 'optimal extended with free poly to square matrix')\n",
    "#plt.plot(Leb_ex4[0], 'yo', label = 'pts cutted to square')\n",
    "plt.ylabel('Lebesgue constant, logscale', rotation=90, labelpad=5)\n",
    "plt.xlabel('Number of expansion terms')\n",
    "fnpdf = dir_points+'Lebesgue on changing designs.pdf'\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(fnpdf)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment setup\n",
    "error_name_set = ['random','lhs','sobol']\n",
    "error_rand = 1\n",
    "error_lhs = 1\n",
    "error_sobol = 1\n",
    "error_mask = np.array((error_rand, error_lhs, error_sobol))\n",
    "error_tens_inx = np.where(error_mask == True)[0].astype(int)\n",
    "error_set = [error_name_set[i] for i in error_tens_inx] \n",
    "solve_all_mesh = False\n",
    "N_iter = 1\n",
    "col_to_fix = []\n",
    "point_to_fix = [\"all\"]\n",
    "slice_coeff = None\n",
    "exp_solve = [[],[],[]]\n",
    "if solve_all_mesh:\n",
    "    exp_solve = [np.unique(np.arange(N_col[0],N_col[-1])),[],None]\n",
    "    exp_plot[0] = col_to_fix\n",
    "    exp_plot[1] = point_to_fix\n",
    "    exp_plot[2] = slice_coeff\n",
    "else:\n",
    "    exp_solve[0] = col_to_fix\n",
    "    exp_solve[1] = point_to_fix\n",
    "    exp_solve[2] = slice_coeff\n",
    "    exp_plot = exp_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = index_preprocess(p_indices,N_col,exp_solve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error calculation\n",
    "# function = [None]\n",
    "mesh  = np.copy(mask)\n",
    "# mesh[:,1] = Nwowge_col[mask[:,1]]\n",
    "mesh[:,1] = ex4.expans[mask[:,1]]\n",
    "mesh[:,0] = ex4.cardinalities\n",
    "#for function in function_set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh1  = np.empty((len(ex1.p_indices), 2))\n",
    "# mesh[:,1] = Nwowge_col[mask[:,1]]\n",
    "mesh1[:,1] = ex1.expans\n",
    "mesh1[:,0] = ex1.cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leb_1 = mult_error_tensor(N_iter, mesh, function, points_test, error_set, shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_d, k_up = ex4.expans[0]-3, ex4.expans[-1]-2\n",
    "ex1.expans = ex1.expans[k_d:k_up]\n",
    "ex1.p_indices = ex1.p_indices[k_d:k_up]\n",
    "ex1.error = ex1.error[k_d:k_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1.expans, ex1.cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4.expans, ex4.cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_name = 'leb_tensor'\n",
    "np.savez(os.path.join(dir_points, tensor_name), error_tensor=leb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if function == [None]:\n",
    "    print('here')\n",
    "    nme = tensor_name = 'error_leb_' + std_design_name + add_name4\n",
    "    print(nme)\n",
    "    tensor_name = nme\n",
    "    error_saved_t = np.load(os.path.join(dir_points, tensor_name) + \".npz\")\n",
    "    error_tensor_r = error_saved_t['error_tensor']\n",
    "else:\n",
    "    \n",
    "    tensor_name = tensor_name = 'error_{}_'.format(function[0].__name__) + std_design_name + add_name4\n",
    "    error_saved_t = np.load(os.path.join(dir_points, tensor_name) + \".npz\")\n",
    "    error_tensor = error_saved_t['error_tensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nme_add = nme + '_add'\n",
    "    error_saved_add = np.load(os.path.join(dir_points, nme_add) + \".npz\")\n",
    "    error_tensor_add = error_saved_add['error_tensor']\n",
    "    error_tensor_r = np.concatenate((error_tensor_r, error_tensor_add), axis = 2)\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "try:\n",
    "    nme_add = nme + '_add2'\n",
    "    error_saved_add = np.load(os.path.join(dir_points, nme_add) + \".npz\")\n",
    "    error_tensor_add = error_saved_add['error_tensor']\n",
    "    error_tensor_r = np.concatenate((error_tensor_r, error_tensor_add), axis = 2)\n",
    "except:\n",
    "    pass   \n",
    "\n",
    "try:\n",
    "    nme_add = nme + '_add3'\n",
    "    error_saved_add = np.load(os.path.join(dir_points, nme_add) + \".npz\")\n",
    "    error_tensor_add = error_saved_add['error_tensor']\n",
    "    error_tensor_r = np.concatenate((error_tensor_r, error_tensor_add), axis = 2)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "try:\n",
    "    nme_add = nme + '_add4'\n",
    "    error_saved_add = np.load(os.path.join(dir_points, nme_add) + \".npz\")\n",
    "    error_tensor_add = error_saved_add['error_tensor']\n",
    "    error_tensor_r = np.concatenate((error_tensor_r, error_tensor_add), axis = 2)\n",
    "except:\n",
    "    pass   \n",
    "\n",
    "try:\n",
    "    nme_add = nme + '_add5'\n",
    "    error_saved_add = np.load(os.path.join(dir_points, nme_add) + \".npz\")\n",
    "    error_tensor_add = error_saved_add['error_tensor']\n",
    "    error_tensor_r = np.concatenate((error_tensor_r, error_tensor_add), axis = 2)\n",
    "except:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tensor = error_tensor_r[error_tens_inx, :, :]\n",
    "print(error_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_tensor_plot_expand(exp_list, mean_tensor, std, error_set, mesh, mesh_opt, dir_points, confidence=False):\n",
    "    fig = plt.figure()\n",
    "    plt.yscale('log')\n",
    "    for k, points_type in enumerate(error_set):\n",
    "        if confidence:\n",
    "            plt.errorbar(mesh[:,0], mean_tensor[k], yerr=std[k],fmt='o', c='g', elinewidth=0.7,alpha=0.5, label='95% CI_' + points_type, ms=1.2)\n",
    "            #c='tab:orange'   \n",
    "        else:\n",
    "            #plt.scatter(mesh[:,0], mean_tensor[k], s=0.7, label=points_type)\n",
    "            plt.plot(mesh[:,0], mean_tensor[k], '--o', linewidth=0.7, label=points_type, markersize=1.2)\n",
    "    \n",
    "    \n",
    "    plt.scatter(mesh[:,0], ex4.error, s=1.5, c='r', label=ex4.name)\n",
    "    plt.scatter(mesh_opt[:,0], ex1.error, s=0.7, label=ex1.name)\n",
    "\n",
    "    plt.xlabel(r'Number of points $k$ in designs $\\xi_k$', fontsize=10)\n",
    "    #plt.xlabel(r'Number of points in designs, $k$', fontsize=10)\n",
    "    fnpdf = dir_points + 'err_leb_expand_n.pdf'\n",
    "   \n",
    "    # plt.ylabel('Approximation error, $\\epsilon$', rotation=90, labelpad=5)\n",
    "    plt.ylabel('Lebesgue constant', rotation=90, labelpad=5)\n",
    "    #plt.legend()\n",
    "    plt.legend(loc = 'upper center',bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.savefig(fnpdf)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_tensor_plot(exp_list, mean_tensor, T_up, T_down, error_set, inx, mask, experiment_params, dir_points,\n",
    "                      confidence=False):\n",
    "    ax = experiment_params[0]\n",
    "    if experiment_params[0] == 2:\n",
    "        ax = 0\n",
    "    fig = plt.figure()\n",
    "    plt.yscale('log')\n",
    "    for k, points_type in enumerate(error_set):\n",
    "        plt.plot(mask[:, ax][inx], mean_tensor[k][inx])#, label=points_type)\n",
    "        if confidence:\n",
    "            plt.fill_between(mask[:, ax][inx], T_down[k][inx], T_up[k][inx], alpha=0.4, label='95% CI_' + points_type)\n",
    "    for i, obj in enumerate(exp_list):\n",
    "        plt.scatter(mask[:, ax][inx], obj.error[inx], s=0.7, label=obj.name)\n",
    "\n",
    "    if experiment_params[0] == 1:\n",
    "        plt.xlabel('Number of basis functions', fontsize=10)\n",
    "        fnpdf = dir_points + 'err(cols)_points={}_func={}.pdf'.format(experiment_params[1], experiment_params[2])\n",
    "    elif experiment_params[0] == 0:\n",
    "        plt.xlabel('Number of points', fontsize=10)\n",
    "        fnpdf = dir_points + 'err(rows)_monoms={}_func={}.pdf'.format(experiment_params[1], experiment_params[2])\n",
    "    else:\n",
    "        plt.xlabel('Number of points', fontsize=10)\n",
    "        fnpdf = dir_points + 'err(points)_coef={}_func={}.pdf'.format(experiment_params[1], experiment_params[2])\n",
    "    # plt.ylabel('Approximation error, $\\epsilon$', rotation=90, labelpad=5)\n",
    "    plt.ylabel('Lebesgue constant', rotation=90, labelpad=5)\n",
    "    plt.legend()\n",
    "    #plt.legend(loc = 'upper center',bbox_to_anchor=(0.5, -0.17), ncol=2)\n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.savefig(fnpdf)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting\n",
    "function_set = function\n",
    "exp_set = [ex1, ex2]\n",
    "if function[0] == None:\n",
    "    func_name = 'None'\n",
    "else:\n",
    "    func_name = function[0].__name__\n",
    "\n",
    "print(error_tensor.shape)\n",
    "z = 1.96   #z-value for 95% confidence interval\n",
    "k = z / np.sqrt(error_tensor.shape[2])    #correcting by a square root from a number of experiments\n",
    "mean_tensor = np.mean(error_tensor,axis = 2)\n",
    "print(mean_tensor.shape)\n",
    "\n",
    "std = np.std(error_tensor, axis = 2)\n",
    "# std[0][4] *= 0.7\n",
    "# std[0][6] *= 0.5\n",
    "#std[1][0] *= 0.65\n",
    "# std[0][-8] *= 0.7\n",
    "\n",
    "T_up = mean_tensor + k * std\n",
    "T_down = mean_tensor - k * std\n",
    "\n",
    "for axis, jx in enumerate(exp_plot[:-1]):\n",
    "    for count, fixed_entity in enumerate(jx):\n",
    "        local_design = [[],[],None]\n",
    "        local_design[axis] = [fixed_entity]\n",
    "        print(local_design)\n",
    "        #sub_mask = index_preprocess(p_indicesn,N_coln,local_design)\n",
    "        #ix_internal = submask(mask, sub_mask)\n",
    "        print('here')\n",
    "        error_tensor_plot(exp_set,mean_tensor,T_up,T_down,error_set, np.arange(66) ,mesh,[axis, fixed_entity,func_name], dir_points, confidence = True)\n",
    "        #error_tensor_plot_expand(exp_set, mean_tensor, k*std, error_set, mesh, mesh1, dir_points, confidence=False)\n",
    "if exp_plot[-1]:\n",
    "    local_design = [[],[],[]]\n",
    "    local_design[2] = exp_plot[-1]\n",
    "    sub_mask = index_preprocess(p_indicesn, N_coln,local_design)\n",
    "    print(mask)\n",
    "    print(sub_mask)\n",
    "    ix_internal = submask(mask, sub_mask)\n",
    "    print('internal',ix_internal)\n",
    "    error_tensor_plot(exp_set,mean_tensor,T_up,T_down,error_set, ix_internal,mask,[2,exp_plot[-1],function.__name__], confidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_down[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(mask == sub_mask[i,:]).all(axis=1).nonzero()[0][0] for i in range(sub_mask.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.yscale('log')\n",
    "plt.plot(np.divide(mean_tensor[0,:], ex1.error), 'ro', label = 'optimal designs')\n",
    "plt.ylabel('Lebesgue constant relation, logscale', rotation=90, labelpad=5)\n",
    "plt.xlabel('Number of expansion terms')\n",
    "fnpdf = dir_points+'nmb_vs_wmxv_pser.pdf'\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(fnpdf)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array((1,2,3,1)), np.array((2,4,5,8)), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random points plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_exp = min_expansion\n",
    "col_exp = 40\n",
    "i = np.where(N_col == col_exp)[0][0]\n",
    "taken_indices = p_indices[i]\n",
    "N_points = len(p_indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_plot(len(p_indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taken_points = np.load(\"piston_10_error.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = taken_points['er']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"piston_10.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_lhs = data['er_lhs']\n",
    "er_r = data['er_r']\n",
    "er_s = data['er_s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_sp(x,y):\n",
    "    b,e = 0.2,0.95\n",
    "    sigma,n = 1/2, 1\n",
    "    r = sp.sqrt(x**2 + y**2)\n",
    "    phi = sp.atan2(y,x)\n",
    "    R = r*sp.sqrt(1 - (e*sp.cos(phi))**2)/b\n",
    "    return((sp.exp(-1*(R**2)/(2*(sigma**2))))*sp.cos(n*phi))\n",
    "\n",
    "def sin_blob_sp(x,y):\n",
    "    a = 0.2\n",
    "    b = 0.8\n",
    "    sigma,n = 1,7\n",
    "    r = sp.sqrt(x**2 + y**2)\n",
    "    phi = sp.atan2(y,x)\n",
    "    R = r*(1/(b + a*sp.cos(n*phi)))\n",
    "    return((sp.exp(-1*(R**2)/(2*(sigma**2))))*(r**2))\n",
    "\n",
    "f_ellipse = symb_to_func(ellipse_sp,    2, True, False, name='Ellipse')  \n",
    "f_sin_blob= symb_to_func(sin_blob_sp,   2, True, False, name='Blob')  \n",
    "\n",
    "f_ellipse.diff    = MakeDiffs(ellipse_sp,  2)\n",
    "f_sin_blob.diff   = MakeDiffs(sin_blob_sp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "a = 1.1\n",
    "X = np.linspace(-a, a, 1000)\n",
    "Y = np.linspace(-a, a, 1000)\n",
    "phi = np.arange(0,2*np.pi, 0.01)\n",
    "b= 0.2\n",
    "e = 0.95\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "#r = (b / np.sqrt(1-(e*np.cos(phi))**2))\n",
    "#xx = r*np.cos(phi)\n",
    "#yy = r*np.sin(phi)\n",
    "\n",
    "r = 0.8 + 0.2*np.cos(7*phi)\n",
    "xx = r*np.cos(phi)\n",
    "yy = r*np.sin(phi)\n",
    "\n",
    "#Z = f_ellipse(X,Y)\n",
    "#Z = f_sin_blob(X,Y)\n",
    "Z = f_gauss_doubl(X,Y) - 2\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.summer,\n",
    "                       linewidth=0,label = 'Trigonometric')\n",
    "#fc = ax.plot(xx, yy,'bo', zs=0, zdir='z', label='curve in (x,y)')\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-1, 1)\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.4, aspect=5)\n",
    "plt.grid(True)\n",
    "#fnpdf = 'ellips.pdf'\n",
    "#plt.savefig(fnpdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = ['0.0','0.01','0.015','0.02','0.025','0.03','0.04','0.05','0.06','0.07','0.08','0.09','0.1','0.11','0.12','0.13','0.15','0.18','0.2','0.25']#,'0.4']\n",
    "funcs = [f_gauss,f_rosenbrock,f_sincos,f_schafferf6,f_roots,f_yaf1,f_gabor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function in funcs:\n",
    "    error_rad = []\n",
    "    #volume = []\n",
    "    for rad in radiuses:\n",
    "        fn = dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\"\n",
    "        N_row, N_col, p_indices = file_extraction(dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\")\n",
    "        ix = index_preproc(N_row,N_col,exp_solve,step_along=1, new_extr_path = None)\n",
    "\n",
    "        #pts = p_indices[ix][0]\n",
    "\n",
    "        #A = GenMat(N_col[ix][0]*(nder+1), x[pts], poly=cheb, debug=False, pow_p=1)\n",
    "        #A = matrix_prep(A, nder+1)\n",
    "        #vol = la.det(A.T @ A)\n",
    "        #volume.append(vol)\n",
    "        bmxvol_error = bmaxvol_error(function,points_test,p_indices,ix)\n",
    "        error_rad.append(bmxvol_error)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 14))\n",
    "\n",
    "    ax.set_xlim(-0.01, 0.26)\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(np.array(radiuses,dtype=float), fontsize=5)\n",
    "    plt.plot(np.array(radiuses,dtype=float),np.array(error_rad)[:,0,0])\n",
    "    plt.xlabel('Erasion radius', fontsize=10)\n",
    "    plt.ylabel('$\\epsilon$')\n",
    "    plt.grid(True)\n",
    "    fnpdf = 'error-rad_fine_func={}.pdf'.format(function.__name__)\n",
    "    plt.savefig(fnpdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted maxvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nder = 1\n",
    "domain_type = None\n",
    "p_size = 4\n",
    "k = 1\n",
    "n_pts = 8000\n",
    "poly_type = poly_power\n",
    "x = complex_area_pnts_gen(n_pts, nder, distrib='lhs', mod = domain_type)*k\n",
    "x_max, x_min = np.round(np.amax(x)),np.floor(np.amin(x))\n",
    "x_bounds = np.array([[-1*k],\n",
    "                      [k]])\n",
    "x = np.vstack((x, x_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GenMat(p_size, x, poly=poly_type, debug=False, pow_p=1,ToGenDiff=True)\n",
    "A = matrix_prep(A, nder+1)\n",
    "#piv = rect_block_maxvol(A, nder, 18, max_iters=200, rect_tol = 0.05, tol = 0.0,debug = False, to_erase = None)\n",
    "perm, C = block_maxvol(A, nder, tol = 0.05, max_iters=200, swm_upd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_block_backward_core(C, P, nder, Kmax, t = 0.05, to_erase=None):\n",
    "    ndim = nder + 1\n",
    "    n, m = C.shape\n",
    "    num_block = n // ndim\n",
    "    k = int(Kmax // ndim)\n",
    "    Fl = True\n",
    "    block_index = m // ndim\n",
    "    non_unique_block_piv = np.copy(P[:m:ndim]//ndim)\n",
    "    block_indcs = P[::ndim]//ndim\n",
    "    S = cold_start_tens(C,ndim)\n",
    "\n",
    "    while Fl and block_index < k:\n",
    "        det_list = la.det(np.eye(ndim) + S)\n",
    "        elem = np.argmax(det_list)\n",
    "        \n",
    "        if det_list[elem] > (1 + t):\n",
    "            range_new_block = np.arange(elem*ndim, elem*ndim + ndim)\n",
    "\n",
    "            \n",
    "            #------ update part -----            \n",
    "            block = np.eye(ndim) + C[range_new_block].dot(C[range_new_block].T)\n",
    "            op3 = C.dot(la.solve(block,C[range_new_block]).T)\n",
    "            op4 = np.dot(op3, C[range_new_block])\n",
    "                   \n",
    "            \n",
    "            C = np.hstack((C - op4, op3))\n",
    "            S = cold_start_tens(C,ndim)\n",
    "        \n",
    "            if not np.isin(block_indcs[elem],non_unique_block_piv):\n",
    "                block_index += 1\n",
    "            \n",
    "            non_unique_block_piv = np.hstack((non_unique_block_piv,block_indcs[elem]))\n",
    "        else:\n",
    "            print('No relevant elements found')\n",
    "            Fl = False\n",
    "    print(block_index)\n",
    "    return(non_unique_block_piv, np.unique(non_unique_block_piv))\n",
    "\n",
    "\n",
    "def brect_backward_naive(A,nder,Kmax,t=0.05):\n",
    "    ndim = nder + 1\n",
    "    n, m = A.shape\n",
    "    k = int(Kmax // ndim)\n",
    "    ids = np.copy(A[:m])\n",
    "    C = np.dot(A,np.linalg.pinv(ids))\n",
    "    \n",
    "    block_index = m // ndim\n",
    "    \n",
    "    block_indcs = np.arange(int(n//ndim))\n",
    "    non_unique_block_piv = np.copy(block_indcs[:(int(m//ndim))])\n",
    "    S = cold_start_tens(C,ndim)\n",
    "    \n",
    "    Fl = True\n",
    "    \n",
    "    test_iter = 0\n",
    "    \n",
    "    while Fl and block_index < k and test_iter < 150:\n",
    "        det_list = la.det(np.eye(ndim) + S)\n",
    "        elem = np.argmax(det_list)\n",
    "        if det_list[elem] > (1 + t):\n",
    "            range_new_block = np.arange(elem*ndim, elem*ndim + ndim)\n",
    "            ids = np.vstack((ids,A[range_new_block]))\n",
    "            \n",
    "            if not np.isin(block_indcs[elem],non_unique_block_piv):\n",
    "                block_index += 1\n",
    "            \n",
    "            non_unique_block_piv = np.hstack((non_unique_block_piv,block_indcs[elem]))\n",
    "            \n",
    "            C = np.dot(A,np.linalg.pinv(ids))\n",
    "            S = cold_start_tens(C,ndim)\n",
    "            test_iter += 1\n",
    "        else:\n",
    "            print('no elements found')\n",
    "            Fl = False\n",
    "    \n",
    "    \n",
    "    return(non_unique_block_piv, np.unique(non_unique_block_piv))\n",
    "\n",
    "def rect_backward_naive(A,Kmax,t=0.01):\n",
    "    def cold_start_S(C):\n",
    "        S = np.empty(C.shape[0])\n",
    "        for i in range(C.shape[0]):\n",
    "            S[i] = C[i] @ C[i].T\n",
    "        return(S)\n",
    "    ndim = 1\n",
    "    n, m = A.shape\n",
    "    ids = np.copy(A[:m])\n",
    "    C = np.dot(A,np.linalg.pinv(ids))\n",
    "    S = cold_start_S(C)\n",
    "    P = np.arange(n)\n",
    "    non_unique_piv = np.copy(P[:m])\n",
    "    row_index = m\n",
    "    Fl = True\n",
    "    test_iter = 0\n",
    "    while Fl and row_index < Kmax and test_iter < 1000:\n",
    "       \n",
    "        elem = np.argmax(S)\n",
    "        #print(S[elem])\n",
    "        if S[elem] > (t):\n",
    "            print(test_iter)\n",
    "            ids = np.vstack((ids,A[elem]))\n",
    "            #print(ids)\n",
    "            if not np.isin(P[elem],non_unique_piv):\n",
    "                row_index += 1\n",
    "            \n",
    "            non_unique_piv = np.hstack((non_unique_piv,P[elem]))\n",
    "            #print(non_unique_piv)\n",
    "            \n",
    "            C = np.dot(A,np.linalg.pinv(ids))\n",
    "            S = cold_start_S(C)\n",
    "            test_iter += 1\n",
    "        else:\n",
    "            print('no elements found')\n",
    "            Fl = False\n",
    "    \n",
    "    \n",
    "    return(non_unique_piv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = maxvol(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_n,idx_o = change_intersept(np.arange(p_size),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[idx_n,:] = A[idx_o,:]\n",
    "x[idx_n] = x[idx_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nup = rect_backward_naive(A,90,t=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr,tt = rect_block_maxvol_core(C, perm, nder, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(la.det(GenMat(p_size, x[:4], poly=poly_type, debug=False, pow_p=1,ToGenDiff=False)))\n",
    "print(la.det(GenMat(p_size, x_bas, poly=poly_type, debug=False, pow_p=1,ToGenDiff=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts,weight = np.unique(nup,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chosen_points(x,pts,weight):\n",
    "    \n",
    "    if x.shape[1] == 1:\n",
    "        plt.figure(figsize=(20,8))\n",
    "        for i,wt in enumerate(weight):\n",
    "            plt.plot(x[pts[i]],1,'bo',mew=0.5+np.log(wt), ms=5)\n",
    "    elif x.shape[1] == 2:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i,wt in enumerate(weight):\n",
    "            plt.plot(x[pts[i],0],x[pts[i],1],'bo',mew=0.5+np.log(wt), ms=5)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chosen_points(x,pts,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_indc = [pt for i, pt in enumerate(pts) if weight[i]>80]\n",
    "basis_indc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas = np.copy(x[basis_indc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uwu(x, A,p_size, poly_type):\n",
    "    c = np.empty(x.shape[0])\n",
    "    for cnt in range(x.shape[0]):\n",
    "        func_vec = GenMat(p_size, np.array([[x[cnt]],]), poly=poly_type, debug=False, pow_p=1,ToGenDiff=False)\n",
    "        c[cnt] = np.dot(func_vec, np.dot(A,func_vec.T))\n",
    "    return(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doom_precise(x, x_bas, n, x_min, x_max):\n",
    "    k = np.abs(x_max - x_min)*0.01*0.5\n",
    "    \n",
    "    for i in range(x_bas.shape[0]):\n",
    "        if x_bas[i] > x_min and x_bas[i] < x_max :\n",
    "            precise = np.linspace(x_bas[i]-k, x_bas[i]+k, n)\n",
    "            precise = np.reshape(precise,(n,1))\n",
    "            x = np.vstack((x,precise))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Domain must include x_bas in the beginning\n",
    "def accurate_debug(p_size, domain, x_bas, n_iter, poly_type, mod = 'argmax'):\n",
    "    def cold_start_S(C):\n",
    "        S = np.empty(C.shape[0])\n",
    "        for i in range(C.shape[0]):\n",
    "            S[i] = C[i] @ C[i].T\n",
    "        return(S)\n",
    "    A_bas = GenMat(p_size, x_bas, poly=poly_type, debug=False, pow_p=1,ToGenDiff=False)\n",
    "    A = GenMat(p_size, domain, poly=poly_type, debug=False, pow_p=1,ToGenDiff=False)\n",
    "    n,m = A.shape\n",
    "    C = np.dot(A,np.linalg.pinv(A_bas))\n",
    "    S = cold_start_S(C)\n",
    "    P = np.arange(n)\n",
    "    non_unique_piv = np.copy(P[:x_bas.shape[0]])\n",
    "    row_index = x_bas.shape[0]\n",
    "        \n",
    "    QF_tensor = np.empty((p_size, p_size, n_iter))\n",
    "    c_tensor = np.empty((n, n_iter))\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        A_bas_inv = la.pinv(A_bas)\n",
    "        QF = (A_bas_inv) @ A_bas_inv.T    \n",
    "        QF_tensor[:,:,i] = QF\n",
    "        c_tensor[:,i] = S \n",
    "        if mod == 'argmax':\n",
    "            elem = np.argmax(S)\n",
    "        else:\n",
    "            elem = np.argmin(S)\n",
    "        #print(i)\n",
    "        A_bas = np.vstack((A_bas,A[elem]))\n",
    "        if not np.isin(P[elem],non_unique_piv):\n",
    "            row_index += 1\n",
    "\n",
    "        non_unique_piv = np.hstack((non_unique_piv,P[elem]))\n",
    "        #print(non_unique_piv)\n",
    "\n",
    "        C = np.dot(A,np.linalg.pinv(A_bas))\n",
    "        S = cold_start_S(C)\n",
    "    \n",
    "    \n",
    "    return(QF_tensor, c_tensor, non_unique_piv)\n",
    "\n",
    "\n",
    "def block_debug(p_size,domain,x_bas,nder,n_iter, poly_type):\n",
    "    ndim = nder + 1\n",
    "    A_bas = GenMat(p_size, x_bas, poly=poly_type, debug=False, pow_p=1,ToGenDiff=True)\n",
    "    A = GenMat(p_size, domain, poly=poly_type, debug=False, pow_p=1,ToGenDiff=True)\n",
    "    \n",
    "    A = matrix_prep(A, nder+1)\n",
    "    A_bas = matrix_prep(A_bas, nder+1)\n",
    "    n, m = A.shape\n",
    "\n",
    "  \n",
    "    C = np.dot(A,np.linalg.pinv(A_bas))\n",
    "    \n",
    "    block_index = m // ndim\n",
    "    \n",
    "    block_indcs = np.arange(int(n//ndim))\n",
    "    non_unique_block_piv = np.copy(block_indcs[:(int(m//ndim))])\n",
    "    S = cold_start_tens(C,ndim)\n",
    "    \n",
    "    QF_tensor = np.empty((p_size, p_size, n_iter))\n",
    "   \n",
    "    for i in range(n_iter):\n",
    "        A_bas_inv = la.pinv(A_bas)\n",
    "        QF = (A_bas_inv) @ A_bas_inv.T    \n",
    "        QF_tensor[:,:,i] = QF\n",
    "        det_list = la.det(np.eye(ndim) + S)\n",
    "        elem = np.argmax(det_list)\n",
    "        \n",
    "        range_new_block = np.arange(elem*ndim, elem*ndim + ndim)\n",
    "        A_bas = np.vstack((A_bas,A[range_new_block]))\n",
    "\n",
    "\n",
    "        non_unique_block_piv = np.hstack((non_unique_block_piv,block_indcs[elem]))\n",
    "\n",
    "        C = np.dot(A,np.linalg.pinv(ids))\n",
    "        S = cold_start_tens(C,ndim)\n",
    "        \n",
    "    return(QF_tensor, non_unique_block_piv)\n",
    "\n",
    "def symbolic_maxvol(p_size,poly_type, x_bas, n_iter, x_min, x_max):\n",
    "    QF_tensor = np.empty((p_size, p_size, n_iter))\n",
    "    xb = np.copy(x_bas)\n",
    "    x_add = []    \n",
    "    x = Symbol('x')\n",
    "    func_list = [x**i for i in range(p_size)]\n",
    "    func_vec = np.array(func_list)\n",
    "    bin_point = np.array([[-20],\n",
    "                           [80]])\n",
    "    for i in range(n_iter):\n",
    "        A_bas = GenMat(p_size, xb, poly=poly_type, debug=False, pow_p=1,ToGenDiff=False)\n",
    "        A_bas_inv = la.pinv(A_bas)\n",
    "        QF = (A_bas_inv) @ A_bas_inv.T    \n",
    "        QF_tensor[:,:,i] = QF\n",
    "        summand = simplify(np.dot(func_vec, QF.dot(func_vec.T)))\n",
    "        \n",
    "        maxs = solve(diff(summand,x,1), x)\n",
    "        maxs.append(x_min)\n",
    "        maxs.append(x_max)\n",
    "        ind = []\n",
    "        for j, maxj in enumerate(maxs):\n",
    "            \n",
    "            if isinstance(maxj, Add):\n",
    "                ind.append(j)\n",
    "        \n",
    "        maxs = [y for z, y in enumerate(maxs) if z not in ind]\n",
    "        \n",
    "        maxs = np.array(maxs, dtype = float)\n",
    "        uwu = np.argmax(fx(QF, maxs))\n",
    "        #p = np.random.randint(2)\n",
    "        x_add.append(maxs[uwu])\n",
    "        #modular = [bin_point[p],x_min,x_max]\n",
    "        #modular = np.array(modular,dtype=float)\n",
    "        #uwu = np.argmax(fx(QF, modular))\n",
    "        xb = np.vstack((xb,maxs[uwu]))\n",
    "        #xb = np.vstack((xb,modular[uwu]))\n",
    "    return(x_add,QF_tensor)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim: \n",
    "#### To see difference in greedy expansion algorithm\n",
    "Run greedy expansion with allowed repetitions / difference is in initial set.\n",
    "May be we can refuse square maxvol in a Vandermonde matrices ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_generator(x, x_bas, ci, shape):\n",
    "    x_bas = np.sort(x_bas, axis = 0)\n",
    "    if ci >= 0.5 :\n",
    "        mask = np.where(np.abs(x - x_bas) < (1-ci))[0]\n",
    "    else:\n",
    "        x_outlyer = np.empty(x_bas.shape[0] - 1)\n",
    "        for i, x_b in enumerate(x_bas[:-1]):\n",
    "            x_outlyer[i] = x_b +  np.abs(x_bas[i+1] - x_b)/2\n",
    "        mask = np.where(np.abs(x - x_outlyer) < ci)[0]#[0] if i==0 else np.vstack((np.where(x - x_out < ci)[0], mask))\n",
    "    nodes = np.random.choice(mask, shape)\n",
    "    return(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment log entry /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basis: 4 poly\n",
    "#### 4 doomed initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_n,idx_o = change_intersept(np.arange(p_size),basis_indc)\n",
    "x[idx_n] = x[idx_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas = np.copy(x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas[0] = 20\n",
    "x_bas[1] =  80\n",
    "x_bas[3] =  -80\n",
    "x_bas[2] = -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ke,QFtS = symbolic_maxvol(p_size,poly_type,x_bas,200,x_min,x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tt = [5,3,1,5]\n",
    "del tt[0]\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QFt, ct, piv = accurate_debug(p_size, x, x_bas, 500,poly_type, mod = 'argmax')\n",
    "#QFt_min, _, piv_min = accurate_debug(p_size, x, x_bas, 300,poly_type, mod = 'argmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_1,weight_1 = np.unique(piv,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[pts_1])\n",
    "print(weight_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chosen_points(x,pts_1,weight_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "t = np.linspace(x_min, x_max, 1000)\n",
    "\n",
    "\n",
    "state_num = QFt.shape[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_state = 7\n",
    "l, = plt.plot(t,uwu(t,QFt[:,:,init_state],p_size, poly_type),'bo')\n",
    "plt.axis([x_min, x_max, 0, 1])\n",
    "\n",
    "axcolor = 'lightgoldenrodyellow'\n",
    "axamp = plt.axes([0.25, 0.15, 0.65, 0.03], facecolor=axcolor)\n",
    "\n",
    "\n",
    "samp = Slider(axamp, 'Evolut', 0, state_num-1, valinit=init_state, valstep=int(1))\n",
    "\n",
    "def update(val):\n",
    "    amp = int(samp.val)\n",
    "    #l.set_ydata(amp*np.sin(2*np.pi*freq*t))\n",
    "    l.set_ydata(uwu(t,QFt[:,:,amp],p_size, poly_type))\n",
    "    \n",
    "    ax.axis([x_min,x_max,0,1.2*np.amax(uwu(t,QFt[:,:,amp],p_size, poly_type))])\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "samp.on_changed(update)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment log entry /3\n",
    "\n",
    "#### basis: 3 poly\n",
    "#### 3 random initial, doomed are hyding in the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment log entry /4\n",
    "\n",
    "#### basis: 4 poly\n",
    "#### Initial set: overdetermined basis FAR FAR away from doomed points\n",
    "Ok, seems that points converge to the doomed ones, and local optima are not always in the doomed points in the beggining of iteration process. Adding points changes matrix of the quadratic form, and therefore changes coefficients of the polynom. But they somehow converge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = basis_generator(x, x_bas, ci = 0.1,shape = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas_x = np.array([[-0.85],\n",
    "                   [0.84],\n",
    "                   [0.778],\n",
    "                   [0.94],\n",
    "                   [-0.89],\n",
    "                   [0.84],\n",
    "                   [0.778],\n",
    "                   [0.94]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_n,idx_o = change_intersept(np.arange(idx.shape[0]),idx)\n",
    "x[idx_n] = x[idx_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bas_overdet = x[:idx.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vstack((x_bas_x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QFt_4, ct_4, piv_4 = accurate_debug(p_size, x, x_bas_x, 200,poly_type,mod='argmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_4,weight_4 = np.unique(piv_4,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pts_4)\n",
    "print(weight_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.where(weight_4>20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[pts_4[mask]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(7/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating test\n",
    "for inital_points_distrib in inital_points_distribs:\n",
    "    points_fn = 'taken_points_{}'.format(inital_points_distrib)\n",
    "    x = complex_area_pnts_gen(num_points_for_big_matrix, nder, distrib='lhs', mod = domain_type)\n",
    "\n",
    "    A = GenMat(p_size, x, poly=poly, debug=False, pow_p=1)\n",
    "    A = matrix_prep(A, nder+1)\n",
    "    \n",
    "    np.savez(os.path.join(dir_str, points_fn), x=x, points_test=points_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fn_pre_pdf = \"distrib={}\".format(inital_points_distrib)\n",
    "    for cut_radius in cut_radiuses:\n",
    "        f = open(os.path.join(dir_str, \"distrib={}_radius={}\".format(inital_points_distrib, cut_radius) + '.txt'), \"w\")\n",
    "        for expansion in range(min_expansion, max_expansion):\n",
    "                    for N_rows_ex in range(max_row, expansion, -1): # It's not the way people do...\n",
    "                        N_rows = N_rows_ex*(nder+1)\n",
    "                        fnpdf = os.path.join(dir_pdf, fn_pre_pdf + \"_expansion={}_N_rows_ex={}.pdf\".format(expansion, N_rows_ex))\n",
    "                        try:\n",
    "                            taken_points = test_bm(A, x,nder, expansion, N_rows, cut_radius = cut_radius,to_save_pivs=N_rows_ex==max_row, \n",
    "                                                       fnpdf=fnpdf)\n",
    "                        except SingularError as err:\n",
    "                            print ('not full column rank with expansion={}, N_rows_ex={}, err={}'.format(\n",
    "                                                                expansion, N_rows_ex, err.value)) \n",
    "                            #continue\n",
    "                            break\n",
    "                            \n",
    "\n",
    "\n",
    "                        taken_points.tofile(f, sep=\" \")\n",
    "                        f.write(\"_Nrows={}_expans={}\\n\".format(N_rows, expansion))\n",
    "                        f.flush()\n",
    "\n",
    "        f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
