{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gen_mat import *\n",
    "from block_rect_maxvol import *\n",
    "import re\n",
    "import os\n",
    "from matplotlib import cm\n",
    "from mva_test import *\n",
    "import itertools\n",
    "from ipywidgets import interactive, interact, widgets\n",
    "%matplotlib inline\n",
    "#matplotlib notebook\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "print (os.environ['OMP_NUM_THREADS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_expr = 1 # Adding this num to output fn for distinguish between experiments  (not used for now)\n",
    "nder = 2 # Dimension\n",
    "ToLoadSet = False # whether to load settigns form file\n",
    "\n",
    "functions = [f_rosenbrock, f_sincos, f_roots, f_gauss]\n",
    "cut_radiuses = [None, 0.125, 0.15, 0.2]\n",
    "inital_points_distribs = ['random', 'LHS']\n",
    "\n",
    "if ToLoadSet:\n",
    "    from sandbox_bm_approx_settings import *\n",
    "else:\n",
    "    dir_str = './'\n",
    "    #dir_str = os.path.join(os.environ['HOME'], 'work/res/bm-big/')\n",
    "    num_points_for_big_matrix = 12000 # number of points for big matrix\n",
    "    max_row =  30                    # Maximum number of points taken in experiments\n",
    "    max_expansion = 20             # number of columns in big matrix in (nder+1) units\n",
    "    min_expansion = 3              # minimal number of columns in experiments in (nder+1) units\n",
    "    \n",
    "\n",
    "    n_test = 50000    # points on test grid (for calculating error on final step)\n",
    "    poly = cheb       # used polinomials\n",
    "    Polar_domain = False\n",
    "\n",
    "\n",
    "#####\n",
    "dir_pdf = os.path.join(dir_str, \"pdf\")\n",
    "try:\n",
    "    os.makedirs(dir_pdf)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "ToTakePointsFromFile = False # (not used for now)\n",
    "\n",
    "# ---------------------------------\n",
    "p_size = (nder+1)*max_row #number of rows in big matrix\n",
    "\n",
    "### generating test points\n",
    "points_test = test_points_gen(n_test, nder, distrib='random') \n",
    "\n",
    "\n",
    "#contents of file sandbox_bm_approx_settings.py\n",
    "_=\"\"\"\n",
    "from gen_mat import cheb\n",
    "\n",
    "\n",
    "dir_str = '.'\n",
    "num_points_for_big_matrix = 50000 # number of points for big matrix\n",
    "max_row = 50                      # Maximum number of points taken in experiments\n",
    "max_expansion = 10                 # number of columns in big matrix in (nder+1) units\n",
    "min_expansion = 1                 # minimal number of columns in experiments in (nder+1) units\n",
    "\n",
    "n_test = 50000    # points on test grid (for calculating error on final step)\n",
    "poly = cheb       # used polynomials\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the new most general environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### evaluating test\n",
    "for inital_points_distrib in inital_points_distribs:\n",
    "    points_fn = 'taken_points_{}'.format(inital_points_distrib)\n",
    "    x = test_points_gen(num_points_for_big_matrix, nder, distrib=inital_points_distrib)\n",
    "    if Polar_domain:\n",
    "        x = domain_erase(x,7)\n",
    "    A = GenMat(p_size, x, poly=poly, debug=False, pow_p=1)\n",
    "    A = matrix_prep(A, nder+1)\n",
    "    \n",
    "    np.savez(os.path.join(dir_str, points_fn), x=x, points_test=points_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fn_pre_pdf = \"distrib={}\".format(inital_points_distrib)\n",
    "    for cut_radius in cut_radiuses:\n",
    "        f = open(os.path.join(dir_str, \"distrib={}_radius={}\".format(inital_points_distrib, cut_radius) + '.txt'), \"w\")\n",
    "        for expansion in range(min_expansion, max_expansion):\n",
    "                    for N_rows_ex in range(max_row, expansion, -1): # It's not the way people do...\n",
    "                        N_rows = N_rows_ex*(nder+1)\n",
    "                        fnpdf = os.path.join(dir_pdf, fn_pre_pdf + \"_expansion={}_N_rows_ex={}.pdf\".format(expansion, N_rows_ex))\n",
    "                        try:\n",
    "                            taken_points = test_bm(A, x,nder, expansion, N_rows, cut_radius = cut_radius,to_save_pivs=N_rows_ex==max_row, \n",
    "                                                       fnpdf=fnpdf)\n",
    "                        except SingularError as err:\n",
    "                            print ('not full column rank with expansion={}, N_rows_ex={}, err={}'.format(\n",
    "                                                                expansion, N_rows_ex, err.value)) \n",
    "                            #continue\n",
    "                            break\n",
    "\n",
    "\n",
    "                        taken_points.tofile(f, sep=\" \")\n",
    "                        f.write(\"_Nrows={}_expans={}\\n\".format(N_rows, expansion))\n",
    "                        f.flush()\n",
    "\n",
    "\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_extraction(Filepath, new_extr = True):\n",
    "    if new_extr:\n",
    "        srch = re.compile(r'([\\d\\s]+)_Nrows=(\\d+)_expans=(\\d+)')\n",
    "        fnd = srch.findall(open(Filepath, 'r').read())\n",
    "        return tuple(np.array(i) for i in zip(*[(int(i1), int(i2), [int(p) for p in im1.strip().split(' ') if len(p) > 0])\n",
    "                                                for im1, i1, i2 in fnd]))\n",
    "    else:\n",
    "        srch = re.compile(r'([\\d\\s]+)_error=([\\+\\-\\d\\.eE]+)_Nrows=(\\d+)_expans=(\\d+)')\n",
    "        fnd = srch.findall(open(Filepath, 'r').read())\n",
    "        return tuple(np.array(i) for i in zip(*[(float(i0), int(i1), int(i2), [int(p) for p in im1.strip().split(' ') if len(p) > 0])\n",
    "                                                for im1, i0, i1, i2 in fnd]))\n",
    "def DataToMesh(error, N_row, N_col, *args):\n",
    "    row_s = sorted(list(set(N_row)))\n",
    "    col_s = sorted(list(set(N_col)))\n",
    "    data = {(N_row[i], N_col[i]) : e for i, e in enumerate(error)}\n",
    "    \n",
    "    res = np.empty((len(row_s), len(col_s)), dtype=float)\n",
    "    for i, r in enumerate(row_s):\n",
    "        for j, c in enumerate(col_s):\n",
    "            try:\n",
    "                res[i,j] = data[(r, c)]\n",
    "            except:\n",
    "                res[i,j] = np.nan\n",
    "    X, Y = np.meshgrid(row_s, col_s)\n",
    "    return res.T, X, Y\n",
    "\n",
    "def PlotError_3D(N_row, N_col, error_ext, log_it=False):\n",
    "    error, N_row, N_col = DataToMesh(error_ext, N_row, N_col)\n",
    "    \n",
    "    if log_it:\n",
    "        error = np.log10(error)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(N_row, N_col, error, edgecolor='black', linewidth=0.5, cmap = cm.Spectral)\n",
    "    # ax.legend()\n",
    "    ax.set_xlabel('N_rows', fontsize=10)\n",
    "    ax.set_ylabel('N_columns')\n",
    "    plt.show()\n",
    "\n",
    "def PlotError(fn, error_ext, cols, rows,k, log_it=False):\n",
    "    ndim = 3\n",
    "    col_start = cols[0]\n",
    "    print col_start\n",
    "    error = error_ext\n",
    "    N_row, N_col,_ = file_extraction(fn, new_extr=True)\n",
    "    if log_it:\n",
    "        error = np.log10(error)\n",
    "    if cols is not None:\n",
    "        if type(cols) is not list:\n",
    "            cols = [cols]\n",
    "        for i in cols:\n",
    "            indx = np.where(N_col == i)\n",
    "            fig = plt.figure()\n",
    "            plt.plot(N_row[indx], error[indx])\n",
    "            plt.xlabel('N_rows', fontsize=10)\n",
    "            plt.ylabel('Error')\n",
    "            fnpdf = 'err(rows)_column={}.pdf'.format(i)\n",
    "            plt.grid(True)\n",
    "            plt.savefig(fnpdf)\n",
    "            plt.close(fig)\n",
    "           \n",
    "    if rows is not None:\n",
    "        if type(rows) is not list:\n",
    "            rows = [rows]\n",
    "        for row in rows:\n",
    "            indx_r = np.where(N_row == row)\n",
    "            fig = plt.figure()\n",
    "            plt.plot(N_col[indx_r], error[indx_r])\n",
    "            plt.xlabel('N_cols', fontsize=10)\n",
    "            plt.ylabel('Error')\n",
    "            fnpdf = 'err(cols)_row={}.pdf'.format(row)\n",
    "            plt.grid(True)\n",
    "            plt.savefig(fnpdf)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            \n",
    "def plot_error_slice(fn, error_ext, slices, rad, log_it=False, to_floor = True, adjust = True, N_adjust = 0):\n",
    "    ndim = 3\n",
    "    error = error_ext\n",
    "    if log_it:\n",
    "        error = np.log10(error)\n",
    "    N_row, N_col,_ = file_extraction(fn, new_extr=True)\n",
    "    cols = np.arange(N_col[0], N_col[-1])\n",
    "    fig = plt.figure() \n",
    "    if adjust == False:\n",
    "        for k in slices:\n",
    "            indx = [] \n",
    "            for i in cols:\n",
    "                if i == 5:\n",
    "                    continue\n",
    "                ix = np.where(N_col == i)[0]\n",
    "                if to_floor:\n",
    "                    loc_indx = np.where(N_row[ix]/ndim == np.floor(k*i))[0]\n",
    "                else:\n",
    "                    loc_indx = np.where(N_row[ix]/ndim == np.ceil(k*i))[0]\n",
    "\n",
    "                try:### to get absolute index - make a summation \n",
    "                    indx.append(loc_indx[0] + ix[0])\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            plt.plot(N_col[indx], error[indx], label = \"k={}\".format(k))\n",
    "    else:\n",
    "        \n",
    "        for k in N_adjust:\n",
    "            indx = []\n",
    "            for i in cols:\n",
    "                if i == 5:\n",
    "                    continue\n",
    "                ix = np.where(N_col == i)[0]    \n",
    "                loc_indx = np.where(N_row[ix] == (i + k)*ndim)[0]\n",
    "                \n",
    "                try:\n",
    "                    indx.append(loc_indx[0] + ix[0])\n",
    "                except:\n",
    "                    continue\n",
    "            plt.plot(N_col[indx], error[indx], label = \"k={}\".format(k))\n",
    "            \n",
    "    plt.legend()\n",
    "    plt.xlabel('N_rows', fontsize=10)\n",
    "    plt.ylabel('Error')\n",
    "    fnpdf = 'err(rows_div_cols)_tofloor={}_adjust={}_rad={}.pdf'.format(to_floor, adjust,rad)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(fnpdf)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data extraction\n",
    "dir_str = './'\n",
    "dir_points = os.path.join(dir_str, \"bm-big4/\")\n",
    "points_distrib = 'LHS'\n",
    "rad = \"0.25\"\n",
    "taken_points = np.load(dir_points + \"taken_points_\" + points_distrib + \".npz\")\n",
    "x = taken_points['x']\n",
    "points_test = taken_points['points_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "### .txt processing\n",
    "functions = [f_branin]\n",
    "\n",
    "N_row, N_col, p_indices = file_extraction(dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\")\n",
    "\n",
    "### old one parsing\n",
    "#pr_error, N_row, N_col,p_inx  = file_extraction(dir_points+\"func=Roots_poly=cheb_distrib=random.txt\", new_extr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.empty(N_row.shape)\n",
    "error_LHS = np.empty(N_row.shape)\n",
    "error_random = np.empty(N_row.shape)\n",
    "error_sobol = np.empty(N_row.shape)\n",
    "Leb = np.empty(N_row.shape)\n",
    "x_LHS = test_points_gen(num_points_for_big_matrix, nder, distrib='LHS')\n",
    "x_random = test_points_gen(num_points_for_big_matrix, nder, distrib='random')\n",
    "x_sobol = GenSobol( N = num_points_for_big_matrix, dim = 2, rng=(-1, 1) )\n",
    "if type(functions) is not list:\n",
    "        functions = [functions]\n",
    "for j, p in enumerate(p_indices):\n",
    "    ValsandNorms = MakeValsAndNorms(functions, points_test)\n",
    "    Leb[j], error[j] = LebesgueConst(x[p], N_col[j]*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "    _, error_LHS[j] = LebesgueConst(x_LHS[p], N_col[j]*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "    _, error_random[j] = LebesgueConst(x_random[p], N_col[j]*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)\n",
    "    _, error_sobol[j] = LebesgueConst(x_sobol[p], N_col[j]*(nder+1), poly=cheb, test_pnts=points_test, pow_p=1, funcs=ValsandNorms, derivative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotError_3D(N_row, N_col, error_random, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_slice(dir_points + \"distrib=\" + points_distrib + \"_radius=0.15.txt\", error,[1.2, 1.3,1.4,1.45, 1.5,1.6,1.7,1.8,1.9],0.25, False, True, False, [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random points plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sobol_lib import *\n",
    "def GenSobol( N = 200, dim = 2, seed = 0, rng=(-1.0, 1.0) ):\n",
    "    res = np.zeros((N, dim), dtype=float)\n",
    "    rng_d = rng[1] - rng[0]\n",
    "    for i in xrange(N):\n",
    "        res[i, :], seed = i4_sobol ( dim, seed )\n",
    "        res[i, :] = res[i, :]*rng_d + rng[0]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_error_slice(fn, k, error, error_LHS, error_random, error_sobol, log_it=False, adjust = False):\n",
    "    N_row, N_col,_ = file_extraction(fn, new_extr=True)\n",
    "    ndim = 3\n",
    "    cols = np.arange(N_col[0], N_col[-1])\n",
    "    fig = plt.figure(figsize=(10,6)) \n",
    "    to_floor = True\n",
    "    if log_it:\n",
    "            error = np.log10(error)\n",
    "            error_LHS = np.log10(error_LHS)\n",
    "            error_random = np.log10(error_random)\n",
    "            error_sobol = np.log10(error_sobol)\n",
    "    if adjust == False:\n",
    "        indx = [] \n",
    "        for i in cols:\n",
    "            if i == 5:\n",
    "                continue\n",
    "            ix = np.where(N_col == i)[0]\n",
    "            if to_floor:\n",
    "                loc_indx = np.where(N_row[ix]/ndim == np.floor(k*i))[0]\n",
    "            else:\n",
    "                loc_indx = np.where(N_row[ix]/ndim == np.ceil(k*i))[0]\n",
    "\n",
    "            try:### to get absolute index - make a summation \n",
    "                indx.append(loc_indx[0] + ix[0])\n",
    "            except:\n",
    "                break\n",
    "    else:\n",
    "        indx = []\n",
    "        for i in cols:\n",
    "            if i == 5:\n",
    "                continue\n",
    "            ix = np.where(N_col == i)[0]    \n",
    "            loc_indx = np.where(N_row[ix] == (i + k)*ndim)[0]\n",
    "\n",
    "            try:\n",
    "                indx.append(loc_indx[0] + ix[0])\n",
    "            except:\n",
    "                continue\n",
    "    N_col = 3*N_col            \n",
    "    plt.plot(N_col[indx], error[indx], label = \"BMaxvol\")\n",
    "    plt.plot(N_col[indx], error_LHS[indx], label = \"LHS\")\n",
    "    plt.plot(N_col[indx], error_random[indx], label = \"Random\")\n",
    "    plt.plot(N_col[indx], error_sobol[indx], label = \"Sobol\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of monoms', fontsize=10)\n",
    "    plt.ylabel('Logscaled error')\n",
    "    plt.grid(True)\n",
    "    fnpdf = 'err(monoms)_slice={}.pdf'.format(k)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(fnpdf)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "def multi_error_straight(fn, error, error_LHS, error_random, error_sobol, col, rows,log_it=False):\n",
    "    ndim = 3\n",
    "    N_row, N_col,_ = file_extraction(fn, new_extr=True)\n",
    "    if log_it:\n",
    "        error = np.log10(error)\n",
    "        error_LHS = np.log10(error_LHS)\n",
    "        error_random = np.log10(error_random)\n",
    "        error_sobol = np.log10(error_sobol)\n",
    "    if col is not None:\n",
    "        cols = np.arange(N_col[0], N_col[-1])\n",
    "        #if type(cols) is not list:\n",
    "           # cols = [cols]\n",
    "        for i in cols:\n",
    "            indx = np.where(N_col == i)\n",
    "            fig = plt.figure()\n",
    "            plt.plot(N_row[indx], error[indx], label = 'BMaxvol')\n",
    "            plt.plot(N_row[indx], error_LHS[indx], label = \"LHS\")\n",
    "            plt.plot(N_row[indx], error_random[indx], label = \"Random\")\n",
    "            plt.plot(N_row[indx], error_sobol[indx], label = \"Sobol\")\n",
    "            plt.xlabel('N_rows', fontsize=10)\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            fnpdf = 'err(rows)_column={}.pdf'.format(i)\n",
    "            plt.grid(True)\n",
    "            plt.savefig(fnpdf)\n",
    "            plt.close(fig)\n",
    "           \n",
    "    if rows is not None:\n",
    "        if type(rows) is not list:\n",
    "            rows = rows.tolist()\n",
    "        for row in rows:\n",
    "            indx = np.where(N_row == row)\n",
    "            fig = plt.figure()\n",
    "            plt.plot(N_col[indx], error[indx], label = 'BMaxvol')\n",
    "            plt.plot(N_col[indx], error_LHS[indx], label = \"LHS\")\n",
    "            plt.plot(N_col[indx], error_random[indx], label = \"Random\")\n",
    "            plt.plot(N_col[indx], error_sobol[indx], label = \"Sobol\")\n",
    "            plt.xlabel('N_cols', fontsize=10)\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            fnpdf = 'err(cols)_row={}.pdf'.format(row)\n",
    "            plt.grid(True)\n",
    "            plt.savefig(fnpdf)\n",
    "            plt.close(fig)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_error_slice(dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\", 1.3, error, error_LHS, error_random, error_sobol, log_it=True, adjust = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_error_straight(dir_points + \"distrib=\" + points_distrib + \"_radius=\" + rad + \".txt\", error, error_LHS, error_random, error_sobol, 1, np.arange(24,84,3,dtype=int),log_it=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate B-maxvol test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_points_for_big_matrix = 1200\n",
    "cut_radiuses = [None, 0.3, 0.025, 0.25]\n",
    "expansion = 12\n",
    "row_exp = 30\n",
    "nder = 2\n",
    "p_size = expansion*(nder+1)\n",
    "distr = 'LHS'\n",
    "x = test_points_gen(num_points_for_big_matrix, nder, distrib=distr)\n",
    "A = GenMat(p_size+3, x, poly=cheb, debug=False, pow_p=1)\n",
    "A = matrix_prep(A, nder+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = np.copy(A)\n",
    "A1 = np.copy(A)\n",
    "A = A1[:,:p_size]\n",
    "fn_pre_pdf = \"distrib={}\".format(distr)\n",
    "for cut_radius in cut_radiuses:\n",
    "    print (np.linalg.norm(A2 - A1,2))\n",
    "    f = open(os.path.join(dir_str, \"distrib={}_radius={}\".format(distr, cut_radius) + '.txt'), \"w\")       \n",
    "    fnpdf = os.path.join(dir_pdf, fn_pre_pdf + \"_expansion={}_N_rows_ex={}.pdf\".format(p_size, row_exp))\n",
    "    try:\n",
    "        if cut_radius == None:\n",
    "            to_erase = None\n",
    "        else:    \n",
    "            erase_init(point_erase, x, nder, r = cut_radius)\n",
    "            to_erase = point_erase\n",
    "        pivs = rect_block_maxvol(A, nder, Kmax = row_exp*(nder+1), max_iters=100, rect_tol = 0.05, tol = 0.0, debug = False, to_erase = to_erase)\n",
    "    except SingularError as err:\n",
    "        print ('not full column rank with expansion={}, N_rows_ex={}, err={}'.format(\n",
    "                                            expansion, row_exp, err.value)) \n",
    "        #continue\n",
    "        break\n",
    "    cut_piv = pivs[:row_exp*(nder+1)]\n",
    "    taken_indices = cut_piv[::(nder+1)] // (nder+1)\n",
    "    \n",
    "\n",
    "    l_bound = np.amin(x, 0)\n",
    "    u_bound = np.amax(x, 0)\n",
    "    delta = (u_bound - l_bound)/20.0\n",
    "    fig = plt.figure()\n",
    "    plt.xlim(l_bound[0] - delta[0], u_bound[0] + delta[0])\n",
    "    plt.ylim(l_bound[1] - delta[1], u_bound[1] + delta[1])\n",
    "    plt.plot(x[pivs[::(nder+1)] // (nder+1), 0], x[pivs[::(nder+1)] // (nder+1), 1], 'b^')\n",
    "    plt.plot(x[taken_indices, 0], x[taken_indices, 1], 'r^')\n",
    "    plt.grid(True)\n",
    "\n",
    "  \n",
    "    fnpdf = 'columns={}_rows={}_rad={}.pdf'.format(expansion*(nder+1), row_exp*(nder+1), cut_radius)\n",
    "\n",
    "    plt.savefig(fnpdf)\n",
    "    plt.close(fig)\n",
    "    taken_indices.tofile(f, sep=\" \")\n",
    "    f.write(\"_Nrows={}_expans={}\\n\".format(row_exp*(nder+1), expansion))\n",
    "    f.flush()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_exp = 18\n",
    "i = np.where(N_col == col_exp)[0][0]\n",
    "taken_indices = p_indices[i]\n",
    "def parameter_plot(N_points):\n",
    "    l_bound = np.amin(x, 0)\n",
    "    u_bound = np.amax(x, 0)\n",
    "    delta = (u_bound - l_bound)/20.0\n",
    "    fig = plt.figure()\n",
    "    plt.xlim(l_bound[0] - delta[0], u_bound[0] + delta[0])\n",
    "    plt.ylim(l_bound[1] - delta[1], u_bound[1] + delta[1])\n",
    "    plt.plot(x[taken_indices[:N_points], 0], x[taken_indices[:N_points], 1], 'r^')\n",
    "    plt.grid(True)\n",
    "    \n",
    "controls = {'N_points': widgets.IntSlider(\n",
    "    min=col_exp, max=max_row, step=1, value=2, continuous_update=False, description='$Points$')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7fe1c908ca4f29bc78eac0310f1758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=18, continuous_update=False, description=u'$Points$', max=30, min=18), O…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(parameter_plot, **controls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_row, N_col, p_indices = file_extraction(dir_points + \"distrib=\" + points_distrib + \"_radius=None.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_exp = 6\n",
    "i = np.where(N_col == col_exp)[0][0]\n",
    "taken_indices = p_indices[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(parameter_plot, **controls);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
